from PIL import Image
import pytesseract
import whisper
from pypdf import PdfReader
from docx import Document
import os
import platform
import re
import unicodedata
from typing import List, Tuple

def configure_tesseract():
    """T·ª± ƒë·ªông c·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n Tesseract OCR"""
    if hasattr(pytesseract.pytesseract, 'tesseract_cmd') and pytesseract.pytesseract.tesseract_cmd:
        configured_path = pytesseract.pytesseract.tesseract_cmd
        if configured_path and os.path.exists(configured_path):
            return  
    
    from dotenv import load_dotenv
    load_dotenv()
    env_path = os.getenv('TESSERACT_CMD')
    
    if env_path:
        env_path = os.path.normpath(env_path.strip().strip('"').strip("'"))
        
        paths_to_try = [env_path]
        if platform.system() == 'Windows' and '/' in env_path:
            paths_to_try.append(env_path.replace('/', '\\'))
        
        for test_path in paths_to_try:
            if os.path.exists(test_path):
                pytesseract.pytesseract.tesseract_cmd = test_path
                return
        
        print(f"‚ö†Ô∏è  TESSERACT_CMD trong .env kh√¥ng t·ªìn t·∫°i: {env_path}")
        print(f"   ƒê√£ th·ª≠ c√°c path: {paths_to_try}")
        print(f"   H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n trong file .env")
    
    if platform.system() == 'Windows':
        username = os.getenv('USERNAME', '')
        possible_paths = [
            r'C:\Program Files\Tesseract-OCR\tesseract.exe',
            r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
            r'C:\Users\{}\AppData\Local\Programs\Tesseract-OCR\tesseract.exe'.format(username),
            r'D:\Program Files\Tesseract-OCR\tesseract.exe',
            r'D:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                pytesseract.pytesseract.tesseract_cmd = path
                return

configure_tesseract()

def process_image_file(file_path: str) -> Tuple[str, str]:
    """
    Extract text t·ª´ image b·∫±ng OCR
    """
    try:
        configure_tesseract()
        
        if not os.path.exists(file_path):
            error_msg = f"File kh√¥ng t·ªìn t·∫°i: {file_path}"
            return '', error_msg
        
        try:
            version = pytesseract.get_tesseract_version()
            print(f"‚úÖ Tesseract OCR version: {version}")
        except Exception as tess_err:
            error_msg = f"Tesseract OCR ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c kh√¥ng t√¨m th·∫•y: {tess_err}. H√£y c√†i Tesseract v√† set TESSERACT_CMD trong .env"
            return '', error_msg
        
        try:
            image = Image.open(file_path)
        except Exception as img_err:
            error_msg = f"Kh√¥ng th·ªÉ m·ªü file ·∫£nh: {img_err}"
            return '', error_msg
        try:
            text = pytesseract.image_to_string(image, lang='vie+eng')
            if text.strip():
                return text, ''
            else:
                error_msg = "OCR tr·∫£ v·ªÅ text r·ªóng - c√≥ th·ªÉ ·∫£nh kh√¥ng c√≥ text, ch·∫•t l∆∞·ª£ng ·∫£nh k√©m, ho·∫∑c text qu√° nh·ªè/m·ªù"
                return '', error_msg
        except Exception as ocr_err:
            print(f"‚ùå Error khi ch·∫°y OCR (vie+eng): {ocr_err}")
            try:
                print("üîÑ Th·ª≠ l·∫°i v·ªõi ch·ªâ ti·∫øng Anh...")
                text = pytesseract.image_to_string(image, lang='eng')
                print(f"‚úÖ OCR (ti·∫øng Anh) th√†nh c√¥ng, ƒë·ªô d√†i text: {len(text)} k√Ω t·ª±")
                if text.strip():
                    return text, ''
                else:
                    error_msg = f"OCR (ti·∫øng Anh) tr·∫£ v·ªÅ text r·ªóng. L·ªói ban ƒë·∫ßu: {ocr_err}"
                    return '', error_msg
            except Exception as ocr_err2:
                error_msg = f"OCR th·∫•t b·∫°i c·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Anh. L·ªói: {ocr_err2}"
                print(f"‚ùå Error khi ch·∫°y OCR (ti·∫øng Anh): {ocr_err2}")
                return '', error_msg
        
    except Exception as e:
        error_msg = f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {type(e).__name__}: {e}"
        print(f"‚ùå Error kh√¥ng x√°c ƒë·ªãnh trong process_image_file: {error_msg}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        return '', error_msg

def process_audio_file(file_path: str) -> str:
    """Transcribe audio th√†nh text b·∫±ng Whisper"""
    try:
        model = whisper.load_model('small')
        res = model.transcribe(file_path)
        return res.get('text','')
    except Exception as e:
        return ''

def process_pdf_file(file_path: str) -> str:
    """
    Extract text t·ª´ PDF file
    H·ªó tr·ª£ PDF c√≥ text layer
    """
    try:
        reader = PdfReader(file_path)
        text_parts = []
        
        for page in reader.pages:
            text = page.extract_text()
            if text:
                text_parts.append(text)
        
        return '\n'.join(text_parts)
    except Exception as e:
        return ''

def process_docx_file(file_path: str) -> str:
    """
    Extract text t·ª´ DOCX file
    H·ªó tr·ª£ .docx format
    """
    try:
        doc = Document(file_path)
        paragraphs = []
        
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                paragraphs.append(text)
        
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text = cell.text.strip()
                    if text:
                        paragraphs.append(text)
        
        return '\n'.join(paragraphs)
    except Exception as e:
        return ''

_BULLET_PATTERN = re.compile(r'^\s*[-‚Ä¢‚óè¬∑]\s+', re.MULTILINE)
_MULTI_SPACE_PATTERN = re.compile(r'\s+')
_EXTRA_PUNCT_PATTERN = re.compile(r'([!?.,;:]){2,}')
_SPACE_BEFORE_PUNCT = re.compile(r'\s+([!?.,;:])')
_SENTENCE_BOUNDARY = re.compile(r'(?<=[.!?])\s+')

COMMON_SPELLING_ERRORS = {
    'ko': 'kh√¥ng',
    'k': 'kh√¥ng',
    'kg': 'kh√¥ng',
    'hok': 'kh√¥ng',
    'khg': 'kh√¥ng',
    'ƒëc': 'ƒë∆∞·ª£c',
    'dc': 'ƒë∆∞·ª£c',
    'dc.': 'ƒë∆∞·ª£c',
    'hok.': 'kh√¥ng',
    'mik': 'm√¨nh',
    'mk': 'm√¨nh',
    'bt': 'b√¨nh th∆∞·ªùng',
    'bh': 'b√¢y gi·ªù',
    'teh': 'the',
    'recieve': 'receive',
    'adress': 'address',
}


def _normalize_unicode(text: str) -> str:
    return unicodedata.normalize('NFC', text)


def _standardize_bullets(text: str) -> str:
    return _BULLET_PATTERN.sub(lambda match: f"\n- ", text)


def _collapse_whitespace(text: str) -> str:
    return _MULTI_SPACE_PATTERN.sub(' ', text)


def _fix_repeated_punctuation(text: str) -> str:
    return _EXTRA_PUNCT_PATTERN.sub(lambda m: m.group(1), text)


def _trim_space_before_punct(text: str) -> str:
    return _SPACE_BEFORE_PUNCT.sub(r'\1', text)


def _basic_spell_correct(text: str) -> str:
    tokens = re.split(r'(\W+)', text)
    corrected: List[str] = []
    for token in tokens:
        key = token.lower()
        if key in COMMON_SPELLING_ERRORS:
            replacement = COMMON_SPELLING_ERRORS[key]
            if token.istitle():
                replacement = replacement.capitalize()
            elif token.isupper():
                replacement = replacement.upper()
            corrected.append(replacement)
        else:
            corrected.append(token)
    return ''.join(corrected)


def _normalize_sentence_spacing(text: str) -> str:
    sentences = [seg.strip() for seg in _SENTENCE_BOUNDARY.split(text) if seg.strip()]
    return ' '.join(sentences)


def clean_text(text: str) -> str:
    """
    L√†m s·∫°ch, chu·∫©n h√≥a text: b·ªè kho·∫£ng tr·∫Øng th·ª´a, chu·∫©n h√≥a d·∫•u c√¢u,
    s·ª≠a c√°c l·ªói ch√≠nh t·∫£ ph·ªï bi·∫øn v√† n·ªëi c√¢u h·ª£p l√Ω.
    """
    if not text:
        return ''
    
    normalized = _normalize_unicode(text)
    normalized = normalized.replace('\r', ' ').strip()
    normalized = _standardize_bullets(normalized)
    normalized = _collapse_whitespace(normalized)
    normalized = _fix_repeated_punctuation(normalized)
    normalized = _trim_space_before_punct(normalized)
    normalized = _basic_spell_correct(normalized)
    normalized = _normalize_sentence_spacing(normalized)
    
    return normalized.strip()
